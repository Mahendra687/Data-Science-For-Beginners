<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "116c5d361fbe812e59a73f37ce721d36",
  "translation_date": "2025-08-27T16:50:11+00:00",
  "source_file": "2-Working-With-Data/07-python/README.md",
  "language_code": "mr"
}
-->
# डेटा सोबत काम करणे: Python आणि Pandas लायब्ररी

| ![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/07-WorkWithPython.png) |
| :-------------------------------------------------------------------------------------------------------: |
|                 Python सोबत काम करणे - _Sketchnote by [@nitya](https://twitter.com/nitya)_                 |

[![Intro Video](../../../../translated_images/video-ds-python.245247dc811db8e4d5ac420246de8a118c63fd28f6a56578d08b630ae549f260.mr.png)](https://youtu.be/dZjWOGbsN4Y)

डेटाबेस डेटा साठवण्यासाठी आणि क्वेरी भाषांचा वापर करून त्यावर क्वेरी करण्यासाठी अत्यंत कार्यक्षम पद्धती प्रदान करतात, परंतु डेटा प्रक्रिया करण्याचा सर्वात लवचिक मार्ग म्हणजे स्वतःचा प्रोग्राम लिहून डेटा हाताळणे. अनेक वेळा, डेटाबेस क्वेरी करणे अधिक प्रभावी ठरते. परंतु काही वेळा जेव्हा अधिक जटिल डेटा प्रक्रिया आवश्यक असते, तेव्हा ती SQL वापरून सहज करता येत नाही. 
डेटा प्रक्रिया कोणत्याही प्रोग्रामिंग भाषेत प्रोग्राम केली जाऊ शकते, परंतु काही भाषा डेटा सोबत काम करण्यासाठी उच्च-स्तरीय मानल्या जातात. डेटा सायंटिस्ट्स सामान्यतः खालील भाषांपैकी एक निवडतात:

* **[Python](https://www.python.org/)**, एक सर्वसामान्य प्रोग्रामिंग भाषा, जी तिच्या साधेपणामुळे सुरुवातीसाठी सर्वोत्तम पर्याय मानली जाते. Python मध्ये अनेक अतिरिक्त लायब्ररी आहेत ज्या तुम्हाला अनेक व्यावहारिक समस्या सोडवण्यास मदत करू शकतात, जसे की ZIP आर्काइव्हमधून डेटा काढणे किंवा चित्र ग्रेस्केलमध्ये रूपांतरित करणे. डेटा सायन्स व्यतिरिक्त, Python वेब डेव्हलपमेंटसाठी देखील मोठ्या प्रमाणावर वापरली जाते. 
* **[R](https://www.r-project.org/)** ही सांख्यिकीय डेटा प्रक्रियेसाठी विकसित केलेली पारंपरिक टूलबॉक्स आहे. यात मोठ्या प्रमाणावर लायब्ररींचे संग्रह (CRAN) आहे, ज्यामुळे ती डेटा प्रक्रियेसाठी चांगला पर्याय ठरते. मात्र, R ही सर्वसामान्य प्रोग्रामिंग भाषा नाही आणि ती डेटा सायन्सच्या क्षेत्राबाहेर क्वचितच वापरली जाते.
* **[Julia](https://julialang.org/)** ही आणखी एक भाषा आहे जी विशेषतः डेटा सायन्ससाठी विकसित केली गेली आहे. Python पेक्षा चांगली कार्यक्षमता देण्यासाठी ती डिझाइन केली गेली आहे, ज्यामुळे ती वैज्ञानिक प्रयोगांसाठी एक उत्कृष्ट साधन बनते.

या धड्यात, आपण साध्या डेटा प्रक्रियेसाठी Python वापरण्यावर लक्ष केंद्रित करू. आम्ही भाषेची प्राथमिक ओळख असल्याचे गृहीत धरतो. जर तुम्हाला Python चा सखोल अभ्यास करायचा असेल, तर तुम्ही खालील संसाधनांचा संदर्भ घेऊ शकता:

* [Learn Python in a Fun Way with Turtle Graphics and Fractals](https://github.com/shwars/pycourse) - Python प्रोग्रामिंगसाठी GitHub-आधारित जलद परिचय कोर्स
* [Take your First Steps with Python](https://docs.microsoft.com/en-us/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum) वरील लर्निंग पाथ

डेटा अनेक स्वरूपात येऊ शकतो. या धड्यात, आपण तीन प्रकारच्या डेटाचा विचार करू - **सारणीबद्ध डेटा**, **मजकूर** आणि **प्रतिमा**.

आपण संबंधित सर्व लायब्ररींचा संपूर्ण आढावा देण्याऐवजी डेटा प्रक्रियेच्या काही उदाहरणांवर लक्ष केंद्रित करू. यामुळे तुम्हाला काय शक्य आहे याची मुख्य कल्पना मिळेल आणि जेव्हा गरज असेल तेव्हा तुमच्या समस्यांचे निराकरण कुठे शोधायचे याचे समज मिळेल.

> **सर्वात उपयुक्त सल्ला**. जेव्हा तुम्हाला डेटावर विशिष्ट ऑपरेशन करायचे असेल आणि ते कसे करायचे हे माहित नसेल, तेव्हा इंटरनेटवर शोधण्याचा प्रयत्न करा. [Stackoverflow](https://stackoverflow.com/) वर अनेक सामान्य कार्यांसाठी Python मधील उपयुक्त कोड नमुने असतात.

## [पूर्व-व्याख्यान क्विझ](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/12)

## सारणीबद्ध डेटा आणि डेटा फ्रेम्स

तुम्ही आधीच सारणीबद्ध डेटाशी परिचित आहात जेव्हा आपण रिलेशनल डेटाबेसबद्दल बोललो होतो. जेव्हा तुमच्याकडे खूप डेटा असतो आणि तो अनेक वेगवेगळ्या लिंक केलेल्या टेबल्समध्ये असतो, तेव्हा त्यावर काम करण्यासाठी SQL वापरणे नक्कीच योग्य ठरते. परंतु अनेक वेळा असे होते की आपल्याकडे डेटा टेबल स्वरूपात असतो आणि आपल्याला या डेटाबद्दल काही **समज** किंवा **अंतर्दृष्टी** मिळवायची असते, जसे की वितरण, मूल्यांमधील परस्परसंबंध इत्यादी. डेटा सायन्समध्ये, अनेक वेळा आपल्याला मूळ डेटाचे काही रूपांतरण करावे लागते, त्यानंतर व्हिज्युअलायझेशन करावे लागते. हे दोन्ही टप्पे Python वापरून सहज करता येतात.

Python मध्ये सारणीबद्ध डेटा हाताळण्यासाठी दोन सर्वात उपयुक्त लायब्ररी आहेत:
* **[Pandas](https://pandas.pydata.org/)** तुम्हाला **Dataframes** हाताळण्याची परवानगी देते, जी रिलेशनल टेबल्ससारखीच असतात. तुम्ही नाव दिलेल्या कॉलम्स असू शकता आणि रो, कॉलम्स आणि डेटा फ्रेम्सवर विविध ऑपरेशन्स करू शकता.
* **[Numpy](https://numpy.org/)** ही **tensors**, म्हणजेच बहु-आयामी **arrays** सोबत काम करण्यासाठी लायब्ररी आहे. Array मध्ये समान प्रकाराच्या मूल्यांचा समावेश असतो, आणि तो डेटा फ्रेमपेक्षा सोपा असतो, परंतु तो अधिक गणितीय ऑपरेशन्स प्रदान करतो आणि कमी ओव्हरहेड निर्माण करतो.

तुम्हाला खालील इतर काही लायब्ररींबद्दल देखील माहिती असणे आवश्यक आहे:
* **[Matplotlib](https://matplotlib.org/)** ही डेटा व्हिज्युअलायझेशन आणि ग्राफ्स प्लॉट करण्यासाठी वापरली जाणारी लायब्ररी आहे
* **[SciPy](https://www.scipy.org/)** ही काही अतिरिक्त वैज्ञानिक फंक्शन्ससाठी लायब्ररी आहे. आपण आधीच संभाव्यता आणि सांख्यिकीबद्दल बोलताना या लायब्ररीचा उल्लेख केला आहे.

खालील कोडचा तुकडा तुम्ही तुमच्या Python प्रोग्रामच्या सुरुवातीला या लायब्ररी आयात करण्यासाठी वापरू शकता:
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import ... # you need to specify exact sub-packages that you need
``` 

Pandas काही मूलभूत संकल्पनांवर केंद्रित आहे.

### Series 

**Series** ही मूल्यांची एक अनुक्रम आहे, जी सूची किंवा numpy array सारखीच आहे. मुख्य फरक असा आहे की series मध्ये **index** देखील असतो, आणि जेव्हा आपण series वर ऑपरेशन करतो (उदा., त्यांना जोडतो), तेव्हा index विचारात घेतला जातो. Index साधा पूर्णांक रो क्रमांक असू शकतो (जेव्हा सूची किंवा array पासून series तयार केली जाते तेव्हा तो डीफॉल्ट index असतो), किंवा त्यात जटिल रचना असू शकते, जसे की तारीख अंतर.

> **Note**: Pandas चा काही परिचयात्मक कोड सोबतच्या नोटबुकमध्ये [`notebook.ipynb`](notebook.ipynb) मध्ये आहे. येथे आपण काही उदाहरणे रेखाटतो, आणि तुम्ही पूर्ण नोटबुक तपासण्यासाठी नक्कीच स्वागत आहे.

उदाहरण विचार करा: आपण आपल्या आईस्क्रीम विक्रीचे विश्लेषण करू इच्छितो. काही कालावधीसाठी विक्रीच्या संख्यांची (प्रत्येक दिवशी विकल्या गेलेल्या वस्तूंची संख्या) series तयार करूया:

```python
start_date = "Jan 1, 2020"
end_date = "Mar 31, 2020"
idx = pd.date_range(start_date,end_date)
print(f"Length of index is {len(idx)}")
items_sold = pd.Series(np.random.randint(25,50,size=len(idx)),index=idx)
items_sold.plot()
```
![Time Series Plot](../../../../translated_images/timeseries-1.80de678ab1cf727e50e00bcf24009fa2b0a8b90ebc43e34b99a345227d28e467.mr.png)

आता समजा प्रत्येक आठवड्यात आपण मित्रांसाठी पार्टी आयोजित करतो आणि पार्टीसाठी 10 अतिरिक्त आईस्क्रीम पॅक्स घेतो. आपण हे दाखवण्यासाठी आठवड्याच्या index ने आणखी एक series तयार करू शकतो:
```python
additional_items = pd.Series(10,index=pd.date_range(start_date,end_date,freq="W"))
```
जेव्हा आपण दोन series एकत्र जोडतो, तेव्हा आपल्याला एकूण संख्या मिळते:
```python
total_items = items_sold.add(additional_items,fill_value=0)
total_items.plot()
```
![Time Series Plot](../../../../translated_images/timeseries-2.aae51d575c55181ceda81ade8c546a2fc2024f9136934386d57b8a189d7570ff.mr.png)

> **Note** की आपण साधा `total_items+additional_items` सिंटॅक्स वापरत नाही. जर आपण तसे केले असते, तर आपल्याला resulting series मध्ये अनेक `NaN` (*Not a Number*) मूल्ये मिळाली असती. याचे कारण असे की `additional_items` series मध्ये काही index पॉइंटसाठी मूल्ये गहाळ आहेत, आणि `NaN` कशालाही जोडल्यास `NaN` मिळते. म्हणूनच, जोडणी दरम्यान `fill_value` पॅरामीटर निर्दिष्ट करणे आवश्यक आहे.

Time series सह, आपण वेगवेगळ्या वेळ अंतरांसह series **resample** देखील करू शकतो. उदाहरणार्थ, समजा आपल्याला मासिक सरासरी विक्री खंडाची गणना करायची आहे. आपण खालील कोड वापरू शकतो:
```python
monthly = total_items.resample("1M").mean()
ax = monthly.plot(kind='bar')
```
![Monthly Time Series Averages](../../../../translated_images/timeseries-3.f3147cbc8c624881008564bc0b5d9fcc15e7374d339da91766bd0e1c6bd9e3af.mr.png)

### DataFrame

DataFrame मूलत: समान index असलेल्या series चा संग्रह आहे. आपण अनेक series एकत्र करून DataFrame तयार करू शकतो:
```python
a = pd.Series(range(1,10))
b = pd.Series(["I","like","to","play","games","and","will","not","change"],index=range(0,9))
df = pd.DataFrame([a,b])
```
यामुळे खालीलप्रमाणे आडव्या स्वरूपातील टेबल तयार होईल:
|     | 0   | 1    | 2   | 3   | 4      | 5   | 6      | 7    | 8    |
| --- | --- | ---- | --- | --- | ------ | --- | ------ | ---- | ---- |
| 0   | 1   | 2    | 3   | 4   | 5      | 6   | 7      | 8    | 9    |
| 1   | I   | like | to  | use | Python | and | Pandas | very | much |

आपण series कॉलम्स म्हणून वापरू शकतो आणि डिक्शनरी वापरून कॉलम नावे निर्दिष्ट करू शकतो:
```python
df = pd.DataFrame({ 'A' : a, 'B' : b })
```
यामुळे खालीलप्रमाणे टेबल तयार होईल:

|     | A   | B      |
| --- | --- | ------ |
| 0   | 1   | I      |
| 1   | 2   | like   |
| 2   | 3   | to     |
| 3   | 4   | use    |
| 4   | 5   | Python |
| 5   | 6   | and    |
| 6   | 7   | Pandas |
| 7   | 8   | very   |
| 8   | 9   | much   |

**Note** की आपण `.T` वापरून मागील टेबल transpose करून देखील हे टेबल लेआउट मिळवू शकतो, उदा. 
```python
df = pd.DataFrame([a,b]).T..rename(columns={ 0 : 'A', 1 : 'B' })
```
येथे `.T` म्हणजे DataFrame चे transpose ऑपरेशन, म्हणजेच रो आणि कॉलम बदलणे, आणि `rename` ऑपरेशन आपल्याला कॉलम्सचे नावे मागील उदाहरणाशी जुळण्यासाठी बदलण्याची परवानगी देते.

DataFrames वर आपण काही महत्त्वाच्या ऑपरेशन्स करू शकतो:

**कॉलम निवडणे**. आपण `df['A']` लिहून वैयक्तिक कॉलम्स निवडू शकतो - ही ऑपरेशन Series परत करते. आपण `df[['B','A']]` लिहून दुसऱ्या DataFrame मध्ये कॉलम्सचा उपसंच निवडू शकतो - हे दुसरे DataFrame परत करते.

**फिल्टरिंग** विशिष्ट निकषांनुसार फक्त काही रांगा. उदाहरणार्थ, कॉलम `A` 5 पेक्षा जास्त असलेल्या रांगा ठेवण्यासाठी आपण `df[df['A']>5]` लिहू शकतो.

> **Note**: फिल्टरिंग कसे कार्य करते ते असे आहे. `df['A']<5` अभिव्यक्ती एक बूलियन series परत करते, जी मूळ series `df['A']` च्या प्रत्येक घटकासाठी अभिव्यक्ती `True` किंवा `False` आहे की नाही हे दर्शवते. जेव्हा बूलियन series index म्हणून वापरली जाते, तेव्हा ती DataFrame मधील रांगांचा उपसंच परत करते. त्यामुळे यादृच्छिक Python बूलियन अभिव्यक्ती वापरणे शक्य नाही, उदाहरणार्थ, `df[df['A']>5 and df['A']<7]` लिहिणे चुकीचे ठरेल. त्याऐवजी, तुम्ही बूलियन series वर विशेष `&` ऑपरेशन वापरावे, उदा. `df[(df['A']>5) & (df['A']<7)]` (*येथे कंस महत्त्वाचे आहेत*).

**नवीन गणनायोग्य कॉलम तयार करणे**. आपण सहजपणे खालीलप्रमाणे अंतर्ज्ञानी अभिव्यक्ती वापरून DataFrame साठी नवीन गणनायोग्य कॉलम तयार करू शकतो:
```python
df['DivA'] = df['A']-df['A'].mean() 
``` 
हे उदाहरण A च्या mean मूल्यापासून त्याचे विचलन मोजते. येथे प्रत्यक्षात काय घडते ते म्हणजे आपण series ची गणना करतो आणि नंतर या series ला डाव्या बाजूला असाइन करतो, नवीन कॉलम तयार करतो. त्यामुळे, आपण series सोबत सुसंगत नसलेल्या कोणत्याही ऑपरेशन्सचा वापर करू शकत नाही, उदाहरणार्थ, खालील कोड चुकीचा आहे:
```python
# Wrong code -> df['ADescr'] = "Low" if df['A'] < 5 else "Hi"
df['LenB'] = len(df['B']) # <- Wrong result
``` 
शेवटचे उदाहरण, व्याकरणदृष्ट्या योग्य असले तरी, आपल्याला चुकीचा परिणाम देते, कारण ते series `B` च्या लांबीला कॉलममधील सर्व मूल्यांना असाइन करते, आणि आपण इच्छित असलेल्या वैयक्तिक घटकांच्या लांबीला नाही.

जर आपल्याला अशा जटिल अभिव्यक्तींची गणना करायची असेल, तर आपण `apply` फंक्शन वापरू शकतो. शेवटचे उदाहरण खालीलप्रमाणे लिहिले जाऊ शकते:
```python
df['LenB'] = df['B'].apply(lambda x : len(x))
# or 
df['LenB'] = df['B'].apply(len)
```

वरील ऑपरेशन्सनंतर, आपल्याला खालील DataFrame मिळेल:

|     | A   | B      | DivA | LenB |
| --- | --- | ------ | ---- | ---- |
| 0   | 1   | I      | -4.0 | 1    |
| 1   | 2   | like   | -3.0 | 4    |
| 2   | 3   | to     | -2.0 | 2    |
| 3   | 4   | use    | -1.0 | 3    |
| 4   | 5   | Python | 0.0  | 6    |
| 5   | 6   | and    | 1.0  | 3    |
| 6   | 7   | Pandas | 2.0  | 6    |
| 7   | 8   | very   | 3.0  | 4    |
| 8   | 9   | much   | 4.0  | 4    |

**संख्यांवर आधारित रांगा निवडणे** `iloc` संरचनेचा वापर करून केले जाऊ शकते. उदाहरणार्थ, DataFrame मधील पहिल्या 5 रांगा निवडण्यासाठी:
```python
df.iloc[:5]
```

**Grouping** अनेकदा Excel मधील *pivot tables* सारखा परिणाम मिळवण्यासाठी वापरले जाते. समजा आपल्याला `LenB` च्या प्रत्येक दिलेल्या संख्येसाठी कॉलम `A` चे mean मूल्य मोजायचे आहे. मग आपण `LenB` द्वारे आपला DataFrame गटबद्ध करू शकतो आणि `mean` कॉल करू शकतो:
```python
df.groupby(by='LenB').mean()
```
जर आपल्याला mean आणि गटातील घटकांची संख्या मोजायची असेल, तर आपण अधिक जटिल `aggregate` फंक्शन वापरू शकतो:
```python
df.groupby(by='LenB') \
 .aggregate({ 'DivA' : len, 'A' : lambda x: x.mean() }) \
 .rename(columns={ 'DivA' : 'Count', 'A' : 'Mean'})
```
यामुळे आपल्याला खालीलप्रमाणे टेबल मिळेल:

| LenB | Count | Mean     |
| ---- | ----- | -------- |
| 1    | 1     | 1.000000 |
| 2    | 1     | 3.000000 |
| 3    | 2     | 5.000000 |
| 4    | 3     | 6.333333 |
| 6    | 2     | 6.000000 |

### डेटा मिळवणे
आम्ही पाहिले आहे की, Python ऑब्जेक्ट्समधून Series आणि DataFrames तयार करणे किती सोपे आहे. मात्र, डेटा सहसा टेक्स्ट फाइल किंवा Excel टेबलच्या स्वरूपात येतो. सुदैवाने, Pandas आपल्याला डिस्कवरून डेटा लोड करण्याचा सोपा मार्ग प्रदान करते. उदाहरणार्थ, CSV फाइल वाचणे इतके सोपे आहे:
```python
df = pd.read_csv('file.csv')
```
आम्ही डेटा लोड करण्याचे अधिक उदाहरणे पाहू, ज्यामध्ये बाह्य वेबसाइट्सवरून डेटा मिळवणे याचाही समावेश आहे, "Challenge" विभागात.

### डेटा प्रिंट करणे आणि प्लॉट करणे

डेटा सायंटिस्टला अनेकदा डेटाचा शोध घ्यावा लागतो, त्यामुळे डेटा व्हिज्युअलाइझ करणे महत्त्वाचे ठरते. जेव्हा DataFrame मोठा असतो, तेव्हा अनेकदा आपण फक्त पहिल्या काही रकाने प्रिंट करून सर्वकाही योग्यरित्या होत आहे याची खात्री करतो. हे `df.head()` कॉल करून करता येते. जर तुम्ही Jupyter Notebook वरून हे चालवत असाल, तर DataFrame एक छान टेबल स्वरूपात प्रिंट होईल.

आम्ही `plot` फंक्शनचा वापर करून काही कॉलम्स व्हिज्युअलाइझ करण्याचा उपयोगही पाहिला आहे. `plot` अनेक कामांसाठी उपयुक्त आहे आणि `kind=` पॅरामीटरद्वारे विविध प्रकारचे ग्राफ्स सपोर्ट करते. मात्र, तुम्ही नेहमीच अधिक जटिल गोष्टी प्लॉट करण्यासाठी raw `matplotlib` लायब्ररी वापरू शकता. डेटा व्हिज्युअलायझेशनचा सविस्तर अभ्यास आम्ही स्वतंत्र कोर्स लेसनमध्ये करू.

ही ओळख Pandas च्या महत्त्वाच्या संकल्पनांचा समावेश करते, मात्र, ही लायब्ररी खूप समृद्ध आहे आणि तुम्ही याचा वापर करून काय करू शकता याला मर्यादा नाही! चला आता या ज्ञानाचा उपयोग विशिष्ट समस्येचे निराकरण करण्यासाठी करूया.

## 🚀 Challenge 1: COVID प्रसाराचे विश्लेषण

आपण लक्ष केंद्रित करणार असलेली पहिली समस्या म्हणजे COVID-19 च्या साथीचा प्रसार मॉडेल करणे. यासाठी, आम्ही विविध देशांतील संक्रमित व्यक्तींच्या संख्येवरील डेटा वापरणार आहोत, जो [Center for Systems Science and Engineering](https://systems.jhu.edu/) (CSSE) ने [Johns Hopkins University](https://jhu.edu/) येथे प्रदान केला आहे. हा डेटासेट [या GitHub Repository](https://github.com/CSSEGISandData/COVID-19) मध्ये उपलब्ध आहे.

आम्ही डेटा कसा हाताळायचा हे दाखवण्यासाठी, तुम्हाला [`notebook-covidspread.ipynb`](notebook-covidspread.ipynb) उघडण्याचे आणि वरपासून खालपर्यंत वाचण्याचे आमंत्रण देतो. तुम्ही सेल्स चालवू शकता आणि शेवटी आम्ही तुमच्यासाठी ठेवलेल्या काही आव्हानांवर काम करू शकता.

![COVID Spread](../../../../translated_images/covidspread.f3d131c4f1d260ab0344d79bac0abe7924598dd754859b165955772e1bd5e8a2.mr.png)

> जर तुम्हाला Jupyter Notebook मध्ये कोड कसा चालवायचा हे माहित नसेल, तर [हा लेख](https://soshnikov.com/education/how-to-execute-notebooks-from-github/) वाचा.

## असंरचित डेटासोबत काम करणे

डेटा अनेकदा टेबल स्वरूपात येतो, परंतु काही प्रकरणांमध्ये आपल्याला कमी संरचित डेटासोबत काम करावे लागते, जसे की टेक्स्ट किंवा प्रतिमा. अशा परिस्थितीत, वरील डेटा प्रक्रिया तंत्र लागू करण्यासाठी, आपल्याला काहीतरी **संरचित डेटा काढणे** आवश्यक असते. येथे काही उदाहरणे आहेत:

* टेक्स्टमधून कीवर्ड्स काढणे आणि ते कीवर्ड किती वेळा दिसतात हे पाहणे
* प्रतिमेतील वस्तूंबद्दल माहिती काढण्यासाठी न्यूरल नेटवर्क्सचा वापर करणे
* व्हिडिओ कॅमेरा फीडवर लोकांच्या भावना जाणून घेणे

## 🚀 Challenge 2: COVID पेपर्सचे विश्लेषण

या आव्हानात, आपण COVID महामारीच्या विषयावर पुढे जाऊ आणि या विषयावरील वैज्ञानिक पेपर्स प्रक्रिया करण्यावर लक्ष केंद्रित करू. [CORD-19 Dataset](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) मध्ये 7000 हून अधिक (लेखनाच्या वेळी) COVID संबंधित पेपर्स उपलब्ध आहेत, ज्यामध्ये मेटाडेटा आणि सारांश (आणि त्यापैकी सुमारे निम्म्यांसाठी पूर्ण मजकूर) समाविष्ट आहे.

[Text Analytics for Health](https://docs.microsoft.com/azure/cognitive-services/text-analytics/how-tos/text-analytics-for-health/?WT.mc_id=academic-77958-bethanycheum) कॉग्निटिव्ह सर्व्हिस वापरून या डेटासेटचे विश्लेषण करण्याचे संपूर्ण उदाहरण [या ब्लॉग पोस्टमध्ये](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/) वर्णन केले आहे. आम्ही या विश्लेषणाचा सरलीकृत आवृत्ती चर्चा करू.

> **NOTE**: आम्ही या रिपॉझिटरीचा भाग म्हणून डेटासेटची प्रत प्रदान करत नाही. तुम्हाला प्रथम [`metadata.csv`](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv) फाइल [या Kaggle डेटासेटवरून](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) डाउनलोड करावी लागेल. Kaggle वर नोंदणी आवश्यक असू शकते. तुम्ही नोंदणीशिवाय [येथून](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html) डेटासेट डाउनलोड करू शकता, परंतु त्यात मेटाडेटा फाइल व्यतिरिक्त सर्व पूर्ण मजकूर समाविष्ट असेल.

[`notebook-papers.ipynb`](notebook-papers.ipynb) उघडा आणि वरपासून खालपर्यंत वाचा. तुम्ही सेल्स चालवू शकता आणि शेवटी आम्ही तुमच्यासाठी ठेवलेल्या काही आव्हानांवर काम करू शकता.

![Covid Medical Treatment](../../../../translated_images/covidtreat.b2ba59f57ca45fbcda36e0ddca3f8cfdddeeed6ca879ea7f866d93fa6ec65791.mr.png)

## प्रतिमा डेटाचे प्रक्रिया करणे

अलीकडे, खूप शक्तिशाली AI मॉडेल्स विकसित केली गेली आहेत जी प्रतिमा समजून घेण्यास सक्षम आहेत. पूर्व-प्रशिक्षित न्यूरल नेटवर्क्स किंवा क्लाउड सेवांचा वापर करून अनेक कार्ये सोडवता येतात. काही उदाहरणे:

* **प्रतिमा वर्गीकरण**, जे तुम्हाला प्रतिमेला पूर्व-परिभाषित वर्गांपैकी एका वर्गात वर्गीकृत करण्यात मदत करू शकते. तुम्ही [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum) सारख्या सेवांचा वापर करून स्वतःचे प्रतिमा वर्गीकरणकर्ता सहजपणे तयार करू शकता.
* **ऑब्जेक्ट डिटेक्शन**, जे प्रतिमेमध्ये वेगवेगळ्या वस्तू शोधू शकते. [Computer Vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum) सारख्या सेवांचा वापर करून सामान्य वस्तू शोधता येतात, आणि [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum) मॉडेल वापरून विशिष्ट वस्तू शोधता येतात.
* **चेहरा ओळख**, ज्यामध्ये वय, लिंग आणि भावना ओळखणे समाविष्ट आहे. हे [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum) च्या मदतीने करता येते.

या सर्व क्लाउड सेवांना [Python SDKs](https://docs.microsoft.com/samples/azure-samples/cognitive-services-python-sdk-samples/cognitive-services-python-sdk-samples/?WT.mc_id=academic-77958-bethanycheum) चा वापर करून कॉल करता येते, आणि त्यामुळे त्या तुमच्या डेटा एक्सप्लोरेशन वर्कफ्लोमध्ये सहजपणे समाविष्ट करता येतात.

### काही उदाहरणे:
* [How to Learn Data Science without Coding](https://soshnikov.com/azure/how-to-learn-data-science-without-coding/) या ब्लॉग पोस्टमध्ये, आम्ही Instagram फोटो एक्सप्लोर करतो, आणि कोणत्या गोष्टींमुळे लोक फोटोला जास्त लाईक्स देतात हे समजून घेण्याचा प्रयत्न करतो. आम्ही प्रथम [Computer Vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum) चा वापर करून फोटोमधून शक्य तितकी माहिती काढतो, आणि नंतर [Azure Machine Learning AutoML](https://docs.microsoft.com/azure/machine-learning/concept-automated-ml/?WT.mc_id=academic-77958-bethanycheum) चा वापर करून एक मॉडेल तयार करतो.
* [Facial Studies Workshop](https://github.com/CloudAdvocacy/FaceStudies) मध्ये, आम्ही [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum) चा वापर करून इव्हेंटमधील लोकांच्या फोटोमधून भावना काढतो, आणि लोकांना आनंदी करणाऱ्या गोष्टी समजून घेण्याचा प्रयत्न करतो.

## निष्कर्ष

तुमच्याकडे संरचित किंवा असंरचित डेटा असो, Python चा वापर करून तुम्ही डेटा प्रक्रिया आणि समजून घेण्याशी संबंधित सर्व पायऱ्या पार करू शकता. डेटा प्रक्रिया करण्याचा हा कदाचित सर्वात लवचिक मार्ग आहे, आणि यामुळेच बहुतेक डेटा सायंटिस्ट Python ला त्यांचे प्राथमिक साधन म्हणून वापरतात. जर तुम्ही तुमच्या डेटा सायन्स प्रवासाबद्दल गंभीर असाल, तर Python सखोल शिकणे ही चांगली कल्पना आहे!

## [Post-lecture quiz](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/13)

## पुनरावलोकन आणि स्व-अभ्यास

**पुस्तके**
* [Wes McKinney. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](https://www.amazon.com/gp/product/1491957662)

**ऑनलाइन संसाधने**
* अधिकृत [10 minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) ट्युटोरियल
* [Pandas Visualization](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) वरचे दस्तऐवज

**Python शिकणे**
* [Learn Python in a Fun Way with Turtle Graphics and Fractals](https://github.com/shwars/pycourse)
* [Take your First Steps with Python](https://docs.microsoft.com/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum) वरील लर्निंग पथ

## असाइनमेंट

[वरील आव्हानांसाठी अधिक सविस्तर डेटा अभ्यास करा](assignment.md)

## क्रेडिट्स

हे लेसन [Dmitry Soshnikov](http://soshnikov.com) यांनी ♥️ सह तयार केले आहे.

---

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर करून उद्भवलेल्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.