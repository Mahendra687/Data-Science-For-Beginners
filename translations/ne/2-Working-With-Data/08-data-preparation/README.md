<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3ade580a06b5f04d57cc83a768a8fb77",
  "translation_date": "2025-08-27T16:46:16+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "ne"
}
-->
# डेटा संग काम गर्ने: डेटा तयारी

|![ [(@sketchthedocs)](https://sketchthedocs.dev) द्वारा स्केच नोट ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|डेटा तयारी - _[@nitya](https://twitter.com/nitya) द्वारा स्केच नोट_ |

## [पाठ अघि क्विज](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/14)

कुनै पनि स्रोतबाट आएको कच्चा डेटा प्रायः असंगतिहरू समावेश गर्न सक्छ, जसले विश्लेषण र मोडलिङमा चुनौतीहरू निम्त्याउँछ। यसलाई "फोहोर" डेटा मान्न सकिन्छ, जसलाई सफा गर्न आवश्यक पर्छ। यो पाठले हराएको, गलत, वा अपूर्ण डेटा समाधान गर्न डेटा सफा गर्ने र परिवर्तन गर्ने प्रविधिहरूमा केन्द्रित छ। यस पाठमा समेटिएका विषयहरू Python र Pandas लाइब्रेरी प्रयोग गरेर [यस निर्देशिकाको नोटबुकमा](notebook.ipynb) प्रदर्शन गरिनेछ।

## डेटा सफा गर्ने महत्त्व

- **प्रयोग र पुन: प्रयोगको सजिलोपन**: जब डेटा राम्रोसँग व्यवस्थित र सामान्यीकृत हुन्छ, यसलाई खोज्न, प्रयोग गर्न, र अरूसँग साझा गर्न सजिलो हुन्छ।

- **संगतता**: डेटा विज्ञानले प्रायः धेरै डेटा सेटहरूसँग काम गर्न आवश्यक पर्छ, जहाँ विभिन्न स्रोतहरूबाट आएका डेटा सेटहरूलाई एकसाथ जोड्नुपर्छ। प्रत्येक व्यक्तिगत डेटा सेटलाई समान मानकीकरण सुनिश्चित गर्दा, सबै डेटा सेटहरूलाई एकसाथ मिलाउँदा पनि उपयोगी रहन्छ।

- **मोडलको शुद्धता**: सफा गरिएको डेटा प्रयोग गर्दा, यसमा आधारित मोडलहरूको शुद्धता सुधार हुन्छ।

## सामान्य सफा गर्ने लक्ष्य र रणनीतिहरू

- **डेटासेट अन्वेषण**: [पछिल्लो पाठ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing) मा समेटिएको डेटा अन्वेषणले सफा गर्नुपर्ने डेटा पत्ता लगाउन मद्दत गर्दछ। डेटासेटभित्रका मानहरूलाई दृश्यात्मक रूपमा अवलोकन गर्दा, बाँकी डेटा कस्तो देखिन्छ भन्ने अपेक्षा गर्न सकिन्छ, वा समाधान गर्न सकिने समस्याहरूको विचार प्राप्त गर्न सकिन्छ। अन्वेषणमा आधारभूत क्वेरी, भिजुअलाइजेसन, र नमूना लिन समावेश हुन सक्छ।

- **फर्म्याटिङ**: स्रोतको आधारमा, डेटा प्रस्तुत गर्ने तरिकामा असंगतिहरू हुन सक्छ। यसले खोजी र मानको प्रतिनिधित्वमा समस्या निम्त्याउन सक्छ, जहाँ डेटासेटभित्र देखिन्छ तर भिजुअलाइजेसन वा क्वेरी परिणामहरूमा सही रूपमा प्रस्तुत हुँदैन। सामान्य फर्म्याटिङ समस्याहरूमा खाली ठाउँ, मिति, र डेटा प्रकार समाधान गर्न समावेश हुन्छ। यी समस्याहरू समाधान गर्ने जिम्मेवारी प्रायः डेटा प्रयोग गर्ने व्यक्तिहरूको हुन्छ। उदाहरणका लागि, मिति र सङ्ख्या प्रस्तुत गर्ने मानक देशअनुसार फरक हुन सक्छ।

- **डुप्लिकेसन**: डेटा जसको एकभन्दा बढी उपस्थिति छ, यसले गलत परिणाम उत्पादन गर्न सक्छ र प्रायः हटाउनुपर्छ। यो दुई वा बढी डेटा सेटहरूलाई जोड्दा सामान्य रूपमा देखिने समस्या हो। तर, कहिलेकाहीँ जोडिएका डेटा सेटहरूमा डुप्लिकेसनले थप जानकारी प्रदान गर्न सक्छ र यसलाई सुरक्षित राख्न आवश्यक हुन सक्छ।

- **हराएको डेटा**: हराएको डेटा गलत परिणामहरू र पक्षपाती नतिजाहरू निम्त्याउन सक्छ। कहिलेकाहीँ यसलाई डेटा पुनः लोड गरेर, Python जस्ता कोड प्रयोग गरेर हराएका मानहरू भरेर, वा केवल मान र सम्बन्धित डेटा हटाएर समाधान गर्न सकिन्छ। डेटा किन र कसरी हरायो भन्ने आधारमा समाधानका उपायहरू फरक हुन सक्छन्।

## DataFrame जानकारी अन्वेषण गर्दै
> **शिक्षण लक्ष्य:** यस उपविभागको अन्त्यसम्ममा, तपाईं pandas DataFrame मा भण्डारण गरिएको डेटा सम्बन्धी सामान्य जानकारी पत्ता लगाउन सहज हुनुहुनेछ।

जब तपाईंले pandas मा आफ्नो डेटा लोड गर्नुहुन्छ, यो प्रायः DataFrame मा हुनेछ (विस्तृत जानकारीको लागि [पछिल्लो पाठ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) हेर्नुहोस्)। तर, यदि तपाईंको DataFrame मा 60,000 पङ्क्ति र 400 स्तम्भ छन् भने, तपाईंले काम गर्नुपर्ने डेटा कस्तो छ भन्ने थाहा कसरी पाउनुहुन्छ? सौभाग्यवश, [pandas](https://pandas.pydata.org/) ले DataFrame को समग्र जानकारी छिटो हेर्नका लागि केही सुविधाजनक उपकरणहरू प्रदान गर्दछ, साथै पहिलो र अन्तिम केही पङ्क्तिहरू हेर्न पनि।

यस कार्यक्षमता अन्वेषण गर्न, हामी Python को scikit-learn लाइब्रेरी आयात गर्नेछौं र एक प्रसिद्ध डेटासेट प्रयोग गर्नेछौं: **Iris डेटा सेट**।

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|
|----------------------------------------|-----------------|----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: सुरु गर्न, `info()` विधि प्रयोग गरेर `DataFrame` मा रहेको सामग्रीको सारांश प्रिन्ट गर्न सकिन्छ। यो डेटासेटमा के छ हेर्नुहोस्:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
यसबाट, हामीलाई थाहा हुन्छ कि *Iris* डेटासेटमा चार स्तम्भहरूमा 150 प्रविष्टिहरू छन् र कुनै पनि null प्रविष्टिहरू छैनन्। सबै डेटा 64-बिट फ्लोटिङ-पोइन्ट सङ्ख्याहरूको रूपमा भण्डारण गरिएको छ।

- **DataFrame.head()**: त्यसपछि, `DataFrame` को वास्तविक सामग्री जाँच गर्न, हामी `head()` विधि प्रयोग गर्छौं। हाम्रो `iris_df` को पहिलो केही पङ्क्तिहरू कस्तो देखिन्छ हेर्नुहोस्:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: विपरीत रूपमा, `DataFrame` को अन्तिम केही पङ्क्तिहरू जाँच गर्न, हामी `tail()` विधि प्रयोग गर्छौं:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **मुख्य कुरा:** DataFrame मा रहेको जानकारीको मेटाडेटा हेर्दा वा पहिलो र अन्तिम केही मानहरू हेर्दा, तपाईंले आफ्नो डेटा कस्तो छ भन्ने आकार, प्रकार, र सामग्रीको तत्काल विचार प्राप्त गर्न सक्नुहुन्छ।

## हराएको डेटा समाधान गर्दै
> **शिक्षण लक्ष्य:** यस उपविभागको अन्त्यसम्ममा, तपाईं DataFrame बाट null मानहरू प्रतिस्थापन गर्न वा हटाउन जान्नुहुनेछ।

प्रायः तपाईंले प्रयोग गर्न चाहने (वा गर्नुपर्ने) डेटासेटहरूमा हराएका मानहरू हुन्छन्। हराएको डेटा कसरी समाधान गरिन्छ भन्ने साना व्यापार-सम्झौताहरू हुन्छन्, जसले तपाईंको अन्तिम विश्लेषण र वास्तविक संसारको परिणामहरूलाई असर गर्न सक्छ।

Pandas ले हराएका मानहरू दुई तरिकाले समाधान गर्छ। पहिलो, जुन तपाईंले अघिल्ला खण्डहरूमा देख्नुभएको छ: `NaN`, वा Not a Number। यो वास्तवमा IEEE फ्लोटिङ-पोइन्ट निर्दिष्टीकरणको एक विशेष मान हो र यो केवल हराएका फ्लोटिङ-पोइन्ट मानहरू संकेत गर्न प्रयोग गरिन्छ।

फ्लोट बाहेकका हराएका मानहरूको लागि, pandas ले Python को `None` वस्तु प्रयोग गर्छ। जबकि `NaN` र `None` ले उस्तै कुरा संकेत गर्छन्, यी दुईको प्रयोगले pandas लाई धेरैजसो अवस्थामा राम्रो सन्तुलन प्रदान गर्न सक्षम बनाउँछ। 

`NaN` र `None` को बारेमा थप जानकारी [नोटबुक](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb) मा हेर्नुहोस्!

- **Null मानहरू पत्ता लगाउँदै**: `pandas` मा, `isnull()` र `notnull()` विधिहरू null डेटा पत्ता लगाउनका लागि मुख्य विधिहरू हुन्। दुवैले Boolean मास्कहरू फिर्ता गर्छन्। हामी `numpy` लाई `NaN` मानहरूको लागि प्रयोग गर्नेछौं:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
आउटपुटलाई ध्यानपूर्वक हेर्नुहोस्। के यसले तपाईंलाई अचम्मित बनायो? 

> **मुख्य कुरा:** `isnull()` र `notnull()` विधिहरूले `DataFrame` मा समान परिणामहरू उत्पादन गर्छन्: यीले परिणामहरू र तिनका अनुक्रमणिका देखाउँछन्, जसले तपाईंलाई डेटा समाधान गर्दा धेरै मद्दत गर्दछ।

- **Null मानहरू हटाउँदै**: Null मानहरू पत्ता लगाउनु बाहेक, pandas ले `Series` र `DataFrame` बाट null मानहरू हटाउन सुविधाजनक उपाय प्रदान गर्दछ। 

```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```

```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```

- **Null मानहरू भर्दै**: कहिलेकाहीँ, null मानहरू हटाउनुको सट्टा तिनलाई वैध मानहरूसँग भर्नु राम्रो हुन्छ। 

```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```

```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```

```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```

```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```

```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```

ध्यान दिनुहोस्, जब अघिल्लो मान उपलब्ध छैन, null मान यथावत् रहन्छ।
> **मुख्य कुरा:** तपाईंको डेटासेटमा हराएका मानहरूलाई व्यवस्थापन गर्न धेरै तरिकाहरू छन्। तपाईंले कुन विशेष रणनीति अपनाउनुहुन्छ (उनीहरूलाई हटाउने, प्रतिस्थापन गर्ने, वा कसरी प्रतिस्थापन गर्ने) त्यो डेटाको विशेषताहरूले निर्धारण गर्छ। डेटासेटसँग धेरै काम गर्दै जाँदा र अन्तरक्रिया गर्दै जाँदा हराएका मानहरूलाई कसरी व्यवस्थापन गर्ने भन्ने राम्रो ज्ञान विकास हुनेछ।

## नक्कल डेटा हटाउने

> **शिक्षण लक्ष्य:** यो उपविभागको अन्त्यसम्ममा, तपाईं DataFrames बाट नक्कल मानहरू पहिचान गर्न र हटाउन सहज हुनुहुनेछ।

हराएको डेटाका अतिरिक्त, तपाईंले वास्तविक संसारका डेटासेटहरूमा प्रायः नक्कल डेटा पनि भेट्नुहुनेछ। सौभाग्यवश, `pandas` ले नक्कल प्रविष्टिहरू पत्ता लगाउन र हटाउन सजिलो माध्यम प्रदान गर्दछ।

- **नक्कल पहिचान गर्ने: `duplicated`**: pandas मा `duplicated` विधि प्रयोग गरेर तपाईं सजिलै नक्कल मानहरू पत्ता लगाउन सक्नुहुन्छ। यसले Boolean मास्क फिर्ता गर्छ, जसले `DataFrame` मा कुनै प्रविष्टि पहिलेको प्रविष्टिको नक्कल हो कि होइन भनेर देखाउँछ। यो क्रियामा हेर्नको लागि अर्को उदाहरण `DataFrame` सिर्जना गरौं।
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |letters|numbers|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **नक्कल हटाउने: `drop_duplicates`:** यसले `duplicated` मानहरू `False` भएका डेटा मात्र समावेश गर्ने प्रतिलिपि फिर्ता गर्छ:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
`duplicated` र `drop_duplicates` दुवैले डिफल्ट रूपमा सबै स्तम्भहरूलाई विचार गर्छन्, तर तपाईं आफ्नो `DataFrame` मा केही स्तम्भहरूको उपसमूह मात्र जाँच गर्न निर्दिष्ट गर्न सक्नुहुन्छ:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **मुख्य कुरा:** नक्कल डेटा हटाउनु लगभग हरेक डेटा-विज्ञान परियोजनाको महत्त्वपूर्ण भाग हो। नक्कल डेटा तपाईंको विश्लेषणको नतिजा परिवर्तन गर्न सक्छ र तपाईंलाई गलत नतिजा दिन सक्छ!

## 🚀 चुनौती

यहाँ छलफल गरिएका सबै सामग्रीहरू [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb) को रूपमा उपलब्ध छन्। साथै, प्रत्येक खण्डपछि अभ्यासहरू पनि छन्, तिनीहरूलाई प्रयास गर्नुहोस्!

## [पोस्ट-व्याख्यान क्विज](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/15)

## समीक्षा र आत्म-अध्ययन

तपाईंको डेटा विश्लेषण र मोडेलिङको लागि तयार पार्न र सफा गर्न धेरै तरिकाहरू छन्, र डेटा सफा गर्नु "व्यावहारिक" अनुभव हो। Kaggle बाट यी चुनौतीहरू प्रयास गर्नुहोस् जसले यस पाठले समेट्न नसकेको प्रविधिहरू अन्वेषण गर्न मद्दत गर्दछ।

- [डेटा सफा गर्ने चुनौती: मिति पार्सिङ](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [डेटा सफा गर्ने चुनौती: स्केल र सामान्यीकरण](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)

## असाइनमेन्ट

[फारमबाट डेटा मूल्याङ्कन गर्ने](assignment.md)

---

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरेर अनुवाद गरिएको हो। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छ। यसको मूल भाषा मा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुने छैनौं।